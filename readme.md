# AI Code Assistant Project
==========================

A simple example project demonstrating how to run a local Family Model using Ollama to create a code assistant application.

## Table of Contents
-----------------

* [Introduction](#introduction)
* [Getting Started](#getting-started)
* [Requirements](#requirements)

## Introduction
---------------

This project is designed to demonstrate the usage of local LLM for building an AI code assistant application. The goal is to create an service that can assist developers in writing better code by analyzing and suggesting improvements in real-time.

## Getting Started
------------------

To get started with this project, you will need to have the following prerequisites:

* Docker installed on your machine (`https://docs.docker.com/get-docker/`)
* follow instruction in file installation.md
* Follow the instructions in [file installation](installation.md)

### Cloning the Repository

Clone the repository using the following command:
```bash
git clone https://github.com/coldwater00/WemosWeatherUnd.git



## Requirements
------------------
Python Libraries
ollearn: For using OLLA in the project.
numpy: For numerical computations.
pandas: For data manipulation and analysis.
#### System Requirements
 * Operating System: Windows, macOS, or Linux.
 * Processor: Any modern processor with a good clock speed. ( Tested on Apple M1)
